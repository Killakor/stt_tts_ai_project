import streamlit as st
import numpy as np
import sounddevice as sd
import tempfile
import wave
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate 
from gtts import gTTS
import os
from datetime import datetime
import matplotlib.pyplot as plt
import altair as alt
from wordcloud import WordCloud
import re
from collections import Counter
from dotenv import load_dotenv
from openai import OpenAI
from pages.database import get_user_role, save_log

## ë³€ìˆ˜
# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=OPENAI_API_KEY)

# ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸
if "logged_in" not in st.session_state or not st.session_state["logged_in"]:
    st.error("ğŸš¨ ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤!")
    st.stop()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (í•„ìˆ˜)
if "logged_in" not in st.session_state:
    st.session_state["logged_in"] = False
if "id" not in st.session_state:
    st.session_state["id"] = None
if "page" not in st.session_state:
    st.session_state["page"] = "login"
if "slider_value" not in st.session_state:
    st.session_state["slider_value"] = 60  # ê¸°ë³¸ ë…¹ìŒ ê¸¸ì´ (ì´ˆ)

# í˜„ì¬ ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´ (KeyError ë°©ì§€)
id = st.session_state.get("id", None)
user_role = get_user_role(id) if id else None

if user_role == "admin":
    name = "ê´€ë¦¬ì"
else: 
    name = "ì…ì‹œë§¤ë‹ˆì €"


## í•¨ìˆ˜
# STT ì²˜ë¦¬ í•¨ìˆ˜
def transcribe_audio(audio_file):
    """ìŒì„± íŒŒì¼ì„ Whisper APIë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    result = client.audio.transcriptions.create(
        model="whisper-1",
        file=audio_file,
        response_format="text"
    )
    return result  # í…ìŠ¤íŠ¸ ë³€í™˜ ê²°ê³¼ ë°˜í™˜

# GPT ìš”ì•½ í•¨ìˆ˜
def generate_summary(text):
    """GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": f"ë‹¤ìŒ ëŒ€í™”ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”:\n\n{text}, ë§Œì•½ ëŒ€í™”ìƒëŒ€ê°€ ë‘ëª… ì´ìƒì´ë©´ ëŒ€í™”ìƒëŒ€ì˜ ì´ë¦„ì„ ëŒ€í™”ë‚´ìš©ì—ì„œ ìœ ì¶”í•˜ì—¬ ì ì–´ì£¼ì„¸ìš”."}],
        temperature=0.7
    )
    return response.choices[0].message.content  # ìš”ì•½ëœ í…ìŠ¤íŠ¸ ë°˜í™˜

# TTS ë³€í™˜ í•¨ìˆ˜
def text_to_speech(text):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    tts = gTTS(text, lang="ko")
    return tts

# ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± í•¨ìˆ˜
def generate_wordcloud(text):
    """ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±"""
    words = re.findall(r'\b\w+\b', text)
    word_freq = Counter(words)
    wordcloud = WordCloud(
        width=900, height=400, background_color="white", font_path="C:/Windows/Font/malgun.ttf"
    ).generate_from_frequencies(word_freq)
    return wordcloud

# GPT ëŒ€í™” ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def get_gpt_response(user_text):
    """GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ì‘ë‹µ ìƒì„±"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": f"ì‚¬ìš©ìì˜ ì§ˆë¬¸: {user_text}\nGPTì˜ ë‹µë³€:"}],
        temperature=0.7
    )
    return response.choices[0].message.content

# ì‚¬ìš©ê°€ëŠ¥ ì˜¤ë””ì˜¤ ì…ë ¥ì¥ì¹˜ í™•ì¸ í•¨ìˆ˜
def get_input_device():
    try:
        devices = sd.query_devices()
        input_devices = [d for d in devices if d['max_input_channels'] > 0]  # ì…ë ¥ ì±„ë„ì´ ìˆëŠ” ì¥ì¹˜ë§Œ í•„í„°ë§
        
        if not input_devices:
            return None  # ì‚¬ìš© ê°€ëŠ¥í•œ ì…ë ¥ ì¥ì¹˜ê°€ ì—†ì„ ê²½ìš°

        return input_devices[0]['index']  # ê¸°ë³¸ì ìœ¼ë¡œ ì²« ë²ˆì§¸ ì…ë ¥ ì¥ì¹˜ ë°˜í™˜
    except Exception as e:
        print(f"âš ï¸ ì˜¤ë””ì˜¤ ì¥ì¹˜ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ë…¹ìŒ í•¨ìˆ˜ (ë””ë°”ì´ìŠ¤ê°€ ì—†ì„ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬)
def record_audio(duration, sample_rate):
    input_device = get_input_device()

    if input_device is None:
        st.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ ì…ë ¥ ì¥ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤! ë§ˆì´í¬ë¥¼ ì—°ê²°í•´ì£¼ì„¸ìš”.")
        return None  # ë…¹ìŒ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ

    try:
        # ë§ˆì´í¬ ë…¹ìŒ ì‹¤í–‰
        recorded_audio = sd.rec(
            int(duration * sample_rate),
            samplerate=sample_rate,
            channels=2,
            dtype=np.int16,
            device=input_device  # ì˜¬ë°”ë¥¸ ì¥ì¹˜ ì‚¬ìš©
        )
        sd.wait()
        return recorded_audio
    except sd.PortAudioError as e:
        st.error(f"âš ï¸ ì˜¤ë””ì˜¤ ì¥ì¹˜ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# íŒŒì¼ ì§€ì • ê²½ë¡œ ìƒì„± í•¨ìˆ˜
def generate_file_path(id, file_name, extension):
    """ì‚¬ìš©ì IDì™€ í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ í•œ íŒŒì¼ëª…ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    folder_path = os.path.join("logs", id)
    
    # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(folder_path, exist_ok=True)

    file_name = f"{id}_{file_name}_{timestamp}.{extension}"
    return os.path.join(folder_path, file_name)


## ë©”ì¸
# Streamlit UI ì„¤ì •
st.set_page_config(page_title="ğŸ™ï¸ ìŒì„± ê¸°ë°˜ AI ìš”ì•½ ì„œë¹„ìŠ¤", layout="wide")

st.image("https://img.uway.com/2021_re/img/logo.png", width=140)
st.title("AI ìŒì„± ìš”ì•½ ì„œë¹„ìŠ¤")
st.info("ğŸ”Š **ìŒì„± íŒŒì¼**ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ **ì‹¤ì‹œê°„ ë…¹ìŒ**í•˜ì—¬ **í…ìŠ¤íŠ¸ ë³€í™˜ ë° ìš”ì•½**ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” ì„¤ì •
if st.session_state["logged_in"]:
    st.sidebar.title(f"**{id}ë‹˜ í™˜ì˜í•©ë‹ˆë‹¤!**")
    st.sidebar.subheader("ê¶Œí•œ: " + name)

    if user_role == "admin":
        page = st.sidebar.radio("ì´ë™í•  í˜ì´ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ë©”ì¸ í˜ì´ì§€", "ë°±ì˜¤í”¼ìŠ¤"])
        if page == "ì‚¬ìš©ì ë©”ì¸":
            st.switch_page("pages/backoffice.py")
        else:
            st.switch_page("pages/main.py")

    # ë¡œê·¸ì•„ì›ƒ ë²„íŠ¼ ì¶”ê°€
    st.sidebar.markdown("---")  
    if st.sidebar.button("ğŸ”’ ë¡œê·¸ì•„ì›ƒ"):
        st.session_state["logged_in"] = False
        st.session_state["id"] = None
        st.session_state["page"] = "login"
        st.rerun()

# ì…ë ¥ ë°©ì‹ ì„ íƒ (íƒ­ í™œìš©)
tab1, tab2 = st.tabs(["ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ™ï¸ ì‹¤ì‹œê°„ ë…¹ìŒ"])
### **TAB 1: íŒŒì¼ ì—…ë¡œë“œ**
with tab1:
    st.subheader("ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("ğŸ“‚ ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["mp3", "wav", "mp4"])

    if uploaded_file is not None:
        with st.spinner("ğŸ› ï¸ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘ì…ë‹ˆë‹¤..."):
            # íŒŒì¼ ì €ì¥ í›„ Whisper API í˜¸ì¶œ
            audio_file_path = generate_file_path(id, "uploaded_audio", uploaded_file.name.split('.')[-1])

            with open(audio_file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            # ì˜¬ë°”ë¥¸ íŒŒì¼ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ STT ë³€í™˜
            with open(audio_file_path, "rb") as audio_file:
                full_text = transcribe_audio(audio_file)

        # STT ê²°ê³¼ í‘œì‹œ (ì•„ì½”ë””ì–¸ í˜•íƒœ)
        with st.expander("ğŸ“Œ ì „ì²´ ëŒ€í™” ë‚´ìš©"):
            st.write(full_text)

        # GPT-4o-mini ìš”ì•½ ìƒì„±
        with st.spinner("ğŸ¤– ë³€í™˜ëœ ìŒì„±ì— ëŒ€í•œ ìš”ì•½ë¬¸ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            summary_text = generate_summary(full_text)

        # ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒìœ¼ë¡œ ìš”ì•½ & ì›Œë“œí´ë¼ìš°ë“œ ë°°ì¹˜
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ğŸ“œ ëŒ€í™” ìš”ì•½ ê²°ê³¼")
            st.write(summary_text)
            st.download_button("ğŸ“¥ ìš”ì•½ íŒŒì¼ ë‹¤ìš´ë¡œë“œ", data=summary_text, file_name=f"{id}_summary.txt")

        with col2:
            # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
            with st.spinner("â˜ï¸ í‚¤ì›Œë“œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                wordcloud = generate_wordcloud(full_text)
                wordcloud_path = generate_file_path(id, "wordcloud", "png")
                wordcloud.to_file(wordcloud_path)

                fig, ax = plt.subplots(figsize=(6, 3))
                ax.imshow(wordcloud, interpolation="bilinear")
                ax.axis("off")
                st.subheader("â˜ï¸ í•µì‹¬ í‚¤ì›Œë“œ")
                st.pyplot(fig)

                # ì›Œë“œí´ë¼ìš°ë“œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ ì¶”ê°€
                with open(wordcloud_path, "rb") as wc_file:
                    st.download_button("ğŸ“¥ í‚¤ì›Œë“œ ë‹¤ìš´ë¡œë“œ", wc_file, file_name=f"{id}_wordcloud.png")

        # TTS ë³€í™˜ ë° ë‹¤ìš´ë¡œë“œ
        with st.spinner("ğŸ”Š í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ ì¤‘ì…ë‹ˆë‹¤..."):
            tts = text_to_speech(summary_text)
            audio_summary_path = generate_file_path(id, "summary_audio", "mp3")
            tts.save(audio_summary_path)

        with open(audio_summary_path, "rb") as audio_file:
            st.download_button("ğŸ“¥ ìš”ì•½ ìŒì„± ë‹¤ìš´ë¡œë“œ", data=audio_file, file_name=f"{id}_summary_audio.mp3")

        # ë¡œê·¸ ì €ì¥ (íŒŒì¼ëª… & ë°ì´í„° ìˆ˜ì •)
        save_log(
            id=id,
            input_type="íŒŒì¼ ì—…ë¡œë“œ",
            original_text=full_text,
            summary_text=summary_text,
            wordcloud_image=wordcloud_path,
            gpt_response=summary_text,
            audio_summary_path=audio_summary_path,
            audio_response_path="N/A"
        )

### **TAB 2: ì‹¤ì‹œê°„ ë…¹ìŒ**
with tab2:
    st.subheader("ğŸ¤ ì‹¤ì‹œê°„ ë…¹ìŒ")

    # ìŠ¬ë¼ì´ë” ìƒíƒœ ìœ ì§€ (í˜ì´ì§€ ë¦¬ë¡œë“œ ì—†ì´ ê°’ë§Œ ì—…ë°ì´íŠ¸)
    duration = st.slider("ë…¹ìŒ ê¸¸ì´ (ì´ˆ)", 30, 1200, st.session_state["slider_value"])

    st.session_state.update({"slider_value": duration})
    sample_rate = 44100  

    if st.button("ğŸ™ï¸ ë…¹ìŒ ì‹œì‘"):
        with st.spinner(f"ğŸ¤ {duration}ì´ˆ ë™ì•ˆ ë…¹ìŒ ì¤‘..."):
            recorded_file_path = generate_file_path(id, "recorded_audio", "wav")
            recorded_audio = record_audio(duration, sample_rate)

        if recorded_audio is not None:
            with wave.open(recorded_file_path, 'wb') as wf:
                wf.setnchannels(2)
                wf.setsampwidth(2)
                wf.setframerate(sample_rate)
                wf.writeframes(recorded_audio.tobytes())

            st.success(f"ğŸ¤ {duration}ì´ˆ ë™ì•ˆ ë…¹ìŒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

        with st.spinner("ğŸ› ï¸ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘ì…ë‹ˆë‹¤..."):
            with open(recorded_file_path, "rb") as audio_file:
                user_text = transcribe_audio(audio_file)

        st.text_area("ğŸ“Œ ì „ì²´ ìŒì„± ë‚´ìš©", user_text, height=500)

        # GPT ìš”ì•½ë¬¸ ìƒì„±
        with st.spinner("ğŸ¤– ë³€í™˜ëœ ìŒì„±ì— ëŒ€í•œ ìš”ì•½ë¬¸ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            summary_text = generate_summary(user_text)

        # GPT ì‘ë‹µ ìƒì„±
        with st.spinner("ğŸ¤– GPT ì‘ë‹µ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            response = get_gpt_response(user_text)

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ğŸ“œ ëŒ€í™” ìš”ì•½ ê²°ê³¼")
            st.write(summary_text)
            st.download_button("ğŸ“¥ ìš”ì•½ íŒŒì¼ ë‹¤ìš´ë¡œë“œ", data=summary_text, file_name=f"{id}_summary.txt")

        with col2:
            # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
            with st.spinner("â˜ï¸ í‚¤ì›Œë“œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                wordcloud = generate_wordcloud(user_text)
                wordcloud_path = generate_file_path(id, "wordcloud", "png")
                wordcloud.to_file(wordcloud_path)

                fig, ax = plt.subplots(figsize=(6, 3))
                ax.imshow(wordcloud, interpolation="bilinear")
                ax.axis("off")
                st.subheader("â˜ï¸ í•µì‹¬ í‚¤ì›Œë“œ")
                st.pyplot(fig)

        # TTS ë³€í™˜ ë° ë‹¤ìš´ë¡œë“œ
        with st.spinner("ğŸ”Š í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ ì¤‘ì…ë‹ˆë‹¤..."):
            tts = text_to_speech(summary_text)
            audio_summary_path = generate_file_path(id, "summary_audio", "mp3")
            tts.save(audio_summary_path)

        with open(audio_summary_path, "rb") as audio_file:
            st.download_button("ğŸ“¥ ìš”ì•½ ìŒì„± ë‹¤ìš´ë¡œë“œ", data=audio_file, file_name=f"{id}_summary_audio.mp3")

        # ë¡œê·¸ ì €ì¥ (íŒŒì¼ëª… & ë°ì´í„° ìˆ˜ì •)
        save_log(
            id=id,
            input_type="ì‹¤ì‹œê°„ ë…¹ìŒ",
            original_text=user_text,
            summary_text=summary_text,
            wordcloud_image=wordcloud_path,
            gpt_response=response,
            audio_summary_path=audio_summary_path,
            audio_response_path="N/A"
        )